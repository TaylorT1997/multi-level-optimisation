{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "\n",
    "    # test_dataset = BinaryTokenTSVDataset(\n",
    "    #     dataset_name=args.dataset,\n",
    "    #     tokenizer=tokenizer,\n",
    "    #     root_dir=args.root,\n",
    "    #     mode=\"test\",\n",
    "    #     token_label_mode=\"first\",\n",
    "    #     include_special_tokens=False,\n",
    "    # )\n",
    "\n",
    "    # test_loader = DataLoader(\n",
    "    #     test_dataset, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn,\n",
    "    # )\n",
    "\n",
    "    sequence_lengths = []\n",
    "    normal_labels = []\n",
    "    extra_labels = []\n",
    "\n",
    "    for idx, (sequences, labels, token_labels) in enumerate(train_loader):\n",
    "        for labels in token_labels:\n",
    "            if len(labels) > 127:\n",
    "                normal_label = max(labels[:127])\n",
    "                extra_label = max(labels[127:])\n",
    "                normal_labels.append(normal_label)\n",
    "                extra_labels.append(extra_label)\n",
    "            sequence_lengths.append(len(labels))\n",
    "\n",
    "    sequence_lengths = np.array(sequence_lengths)\n",
    "\n",
    "    print(f\"Num samples: {len(sequence_lengths)}\")\n",
    "    print(f\"Num over 128: {sum(sequence_lengths>127)}\")\n",
    "    print(normal_labels)\n",
    "    print(extra_labels)\n",
    "    print(sum(extra_labels))\n",
    "\n",
    "    sequence_lengths = []\n",
    "    normal_labels = []\n",
    "    extra_labels = []\n",
    "\n",
    "    for idx, (sequences, labels, token_labels) in enumerate(val_loader):\n",
    "        for labels in token_labels:\n",
    "            if len(labels) > 127:\n",
    "                normal_label = max(labels[:127])\n",
    "                extra_label = max(labels[127:])\n",
    "                normal_labels.append(normal_label)\n",
    "                extra_labels.append(extra_label)\n",
    "            sequence_lengths.append(len(labels))\n",
    "\n",
    "    sequence_lengths = np.array(sequence_lengths)\n",
    "\n",
    "    print(f\"Num samples: {len(sequence_lengths)}\")\n",
    "    print(f\"Num over 128: {sum(sequence_lengths>127)}\")\n",
    "    print(normal_labels)\n",
    "    print(extra_labels)\n",
    "    print(sum(extra_labels))\n",
    "\n",
    "    # sequence_lengths = []\n",
    "    # normal_labels = []\n",
    "    # extra_labels = []\n",
    "    # extra_labels_len = []\n",
    "    # all_toks = 0\n",
    "\n",
    "    # for idx, (sequences, labels, token_labels) in enumerate(test_loader):\n",
    "    #     for labels in token_labels:\n",
    "    #         if len(labels) > 128:\n",
    "    #             normal_label = max(labels[:127])\n",
    "    #             extra_label = max(labels[127:])\n",
    "    #             extra_label_len = len(labels[127:])\n",
    "    #             normal_labels.append(normal_label)\n",
    "    #             extra_labels.append(extra_label)\n",
    "    #             extra_labels_len.append(extra_label_len)\n",
    "    #         sequence_lengths.append(len(labels))\n",
    "    #         all_toks += len(labels)\n",
    "\n",
    "    # sequence_lengths = np.array(sequence_lengths)\n",
    "\n",
    "    # print(f\"Num samples: {len(sequence_lengths)}\")\n",
    "    # print(f\"Num over 128: {sum(sequence_lengths>127)}\")\n",
    "    # print(normal_labels)\n",
    "    # print(extra_labels)\n",
    "    # print(sum(extra_labels))\n",
    "    # print(extra_labels_len)\n",
    "    # print(sum(extra_labels_len))\n",
    "    # print(all_toks)\n",
    "\n",
    "    sys.exit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abb2cb76335e17f998bb1c45cf54676892e04cee9701593aebf3ae470b0ae763"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('mlo': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}